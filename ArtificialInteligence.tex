\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}

%opening
\title{Artificial Intelligence \\ notes}
\author{Klara Malinowska}

\begin{document}

\maketitle
\section{Welcome to AI}
\section{Problem Solving}

Complexity may come from large number of possible choices or from partial observability.

\paragraph{Definition of an problem}
The problem may be defined by a set of states and functions
\begin{enumerate}
  \item Initial state $s$
  \item Action($s$) $\rightarrow$ $a$ There may be a lot of them forming a set ${a_1, a_2, ...}$ and they may be dependent or independent on a current state
  \item Result($s,a$) $\rightarrow$ $s'$ Taking initial state and a chosen action gives us the resulting state.
  \item GoalTest($s$) $\rightarrow$ $s'$ T|F Takes a current states and checks if it is a solution. Returns boolean value.
  \item PathCost($s,a,s,a,s,...$) $\rightarrow$ $n$ Takes sequence of steps and actions and gives a cost of it as a number. Usually is an additive fuction of StepCosts
  \item StepCost($s,a,s'$) $rightarrow$ $n$ Gives a cost of one action as a number.
\end{enumerate}

States space divides into explored part, frontier (which are the farthest state explored) and unexplored part.

A problem solving technology works only if:
\begin{enumerate}
 \item domain fully observable (we know exactly the current state)
 \item domain is known (known set of available actions)
 \item discrete domain (limited amount of possible actions)
 \item deterministic domain (result of an action is known)
 \item static domain (nothing changes the space state but we)
\end{enumerate}


\subsection{Path searching}

\paragraph{Tree search vs. graph search} 

The two search algorithms differ in ``having memory'' - remembering which states are already explored. The tree algorithm does not do that, so it can go back with the explored path to the state it has already been in. The graph search remembers where it has already been and thus never goes back to the previously visited states.
\paragraph{Tree search}
\begin{verbatim}
function Tree.Search(problem)
  frontier = {[initial]}
  loop:
    if frontier is empty: return FAIL
    path = remove_choice(frontier)
    s = path.end
    if s is a goal: return path
    for a in actions:
      add [path + a -> Result(s,a)] to frontier
\end{verbatim}

\paragraph{Graph search}
\begin{verbatim}
function Tree.Search(problem)
  frontier = {[initial]}
  explored = {}
  loop:
    if frontier is empty: return FAIL
    path = remove_choice(frontier)
    s = path.end
    add s to explored
    if s is a goal: return path
    for a in actions:
      add [path + a -> Result(s,a)] to frontier 
      unless Result(s,a) in frontier + explored
\end{verbatim}

\paragraph{Breadth first search}
Always chooses the shortest (in term of steps) path to explore next. If there are paths of the same length, it chooses randomly. Is guaranteed to find the shortest (in terms of number of steps) path. Requires storage space of $2^n$ paths to store all the nodes in the frontier.

\paragraph{Uniform-cost search - cheapest first}
It chooses which path to explore next basing on the path cost. Is guaranteed to find the cheapest path, because even if it has already added the goal to the frontier, it firstly explores all the shorter paths and only when the one leading to the goal is the shortest it performs the goal check. Number of paths in the frontier is similar that in the breadth first algorithm.

\paragraph{Depth first search}
It chooses the longest path to explore first. It is not optimal - does not guarantee to find the best solution (path that reaches the goal in the minimal amount of steps). Requires storage space of $n$ to store all the nodes in the frontier.

\paragraph{Number of nodes in the frontier}
It is $2^n$ for the breadth first search and similar in the uniform-cost search. It is $n$ in the depth first search. Thus depth first search requires much less memory than the other two when we save the frontier only. However, if we save also explored space, all three algorithms need the similar amount of memory.

\paragraph{Completeness}
Algorithm is complete if it will always find the optimal path. Breadth first and uniform-cost search algorithms are complete. The depth first search algorithm is not.

\paragraph{Greedy best-first search}
It needs additional information to work, eg. estimate of the distance of the start state to the goal such as straight line distance from the state to the goal. It explores much smaller part of the states space that the uniform-cost search, and therefore shall be faster. However, it may not find the shortest path (if it requires going in the direction ``from'' the goal in some steps) - it is not complete.

\subsection{A* search}
The A* search combines the uniform-cost search and greedy best-first search in its way to determine which path to explore. It chooses the path to explore minimizing on the function h(path) which adds the path cost up to certain state as well as distance from the goal.
\begin{verbatim}
f(path) = g(path) + h(path)
g(path) = path.cost
h(path) = h(s) = current distance to the goal
\end{verbatim}

The A* algorithm will always find the lowest cost path if h(s) function is smaller than a true cost to get to the goal from a current state. It should never overestimate the cost to get to the goal, an thus is an  optimistic. Such an h is called \textbf{admissable} (it is admissible to use it to find a lowest cost path). 
\end{document}


